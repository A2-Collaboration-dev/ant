#!/usr/bin/perl
use strict;
use warnings;
use Getopt::Long;

use Cwd qw(abs_path);
use File::Path qw(rmtree mkpath);
use File::Basename qw(basename);
use Text::ParseWords;
use POSIX;
use IPC::Open2;

my $filelist = '-';             # default STDIN
my $clean = 0;
my $help = 0;
my $cmd_plot = 'Ant-plot';
my $cmd_hadd = 'Ant-hadd';
my $cmd_chain = 'Ant-chain';
my $jobtag = 'Ant';
my $n_mult = 10;
my $n_chain = 10;
my $QSUB_BIN = 'qsub';
my $queue = 'dflt';
my $walltime = '2:00:00';       # dflt_short has 2h walltime
my $plotargs = '';
my @plotternames;


# parse options
Getopt::Long::Configure(qw(gnu_getopt));
GetOptions(
           'help|h' => \$help,
           'clean|c' => \$clean,
           'plotargs=s' => \$plotargs,
           'plot|p=s' => \@plotternames,
           'cmd_plot=s' => \$cmd_plot,
           'cmd_hadd=s' => \$cmd_hadd,
           'tag|t=s' => \$jobtag,
           'filelist=s' => \$filelist,
           'mult=s' => \$n_mult,
           'chain=s' => \$n_chain,
           'queue=s' => \$queue,
           'walltime=s' => \$walltime,
          ) or print_help();
if ($help) {
  print_help();
}

# plotargs is passed globally to create_map_submission
for my $plottername (@plotternames) {
  $plotargs .= " -p $plottername";
}

my $WORKDIR = 'AntMapReduce.'.$jobtag;
my $OUTFILE = $jobtag.'.root';

&main;

sub main {
  if ($cmd_plot ne '') {
    $cmd_plot = which($cmd_plot);
    die "Plot program not found" unless defined $cmd_plot;
    # sanity check for default plot tool called Ant-plot
    die "Neither plotter names nor --plotargs specified" if $cmd_plot eq 'Ant-plot' && $plotargs eq ''
  }
  $cmd_hadd = which($cmd_hadd);
  die "hadd program not found" unless defined $cmd_hadd;
  $cmd_chain = which($cmd_chain);
  die "Chain program not found" unless defined $cmd_chain;

  if (-e $WORKDIR || -e $OUTFILE || -e "$OUTFILE.log") {
    if ($clean) {
      rmtree($WORKDIR);
      unlink $OUTFILE;
      unlink "$OUTFILE.log";
      print "Cleaned outputfile '$OUTFILE', '$OUTFILE.log' and workdir\n";
    } else {
      die "Outputfile '$OUTFILE' (and maybe workdir $WORKDIR) already exists, use --clean maybe?";
    }
  }

  # make map for easier lookup
  my %jobs_in_queue = map {$_=>1} &get_jobs_in_queue;

  open(my $filelist_fh, "<$filelist") or die "Can't open filelist $filelist: $!\n";
  my @inputs;
  my $notInQueue = 0;
 line:
  while (my $line = <$filelist_fh>) {
    # remove leading and trailing whitespace
    $line =~ s/^\s+//;
    $line =~ s/\s+$//;
    my($inputfile, $jobid) = split(/\s+/, $line);
    unless(-f $inputfile) {
      unless(defined $jobid) {
        warn "Warning: Inputfile $inputfile does not exist, skipping.";
        next line;
      }
    }

    # strip .farm.kph in jobid, AntSubmit already provides this,
    # but user may have other sources of jobids...
    if (defined $jobid) {
      if ($jobid =~ /\./) {
        # strip farm.kph string, to match qstat output, sigh
        $jobid = join('.',(split /\./, $jobid)[0..1]);
      }

      # check if provided jobid is in queue (otherwise qsub will complain)
      if (!$jobs_in_queue{$jobid}) {
        # warn "Warning: Jobid $jobid not in queue, skipping.";
        $notInQueue++;
        next line;
      }
    }

    push(@inputs, {
                   'inputfile' => abs_path($inputfile),
                   'jobid' => $jobid,
                  }
        );
  }
  close $filelist_fh;

  warn "Skipped $notInQueue jobs with provided jobids as they were not found in queue" if $notInQueue>0;

  die "No inputs to be submitted, nothing to do.\n" if @inputs==0;


  # ensure our temp outputdir is there
  mkdir $WORKDIR or die "Can't create workdir $WORKDIR: $!";

  # create map submissions from jobs and submit them directly
  # those are the leaves for the reduction tree, see below
  my @reduce_inputs;

  if ($cmd_plot ne '') {
    # aggregate jobs from inputfiles
    my @map_jobs = aggregate(\@inputs, $n_chain);

    for my $job (@map_jobs) {
      my $sub = create_map_submission($job);
      my $jobid = submit_job($sub);
      push(@reduce_inputs,
           {
            'inputfile' => $sub->[2], # next input is previous output...
            'jobid' => $jobid
           });
    }
  } else {
    # do not execute map step at all, but do reduce only
    @reduce_inputs = @inputs;
  }

  # create reduce submissions, until we reach one single job
  my $level = 0;
  while (1) {
    my @reduce_jobs = aggregate(\@reduce_inputs, $n_mult, $level);

    if (@reduce_jobs == 1) {
      # one last job left, then create submission to final output
      my $sub = create_reduce_submission($reduce_jobs[0], 1);
      my $jobid = submit_job($sub);
      print "Final output $OUTFILE will be created by job $jobid\n";
      last;                     # exit while
    }

    @reduce_inputs = ();
    for my $job (@reduce_jobs) {
      my $sub = create_reduce_submission($job);
      my $jobid = submit_job($sub);
      push(@reduce_inputs,
           {
            'inputfile' => $sub->[2], # next input is previous output...
            'jobid' => $jobid
           });
    }
    $level++;
  }
}

sub aggregate {
  my @inputs = @{shift()};
  my $n_perJob = shift;
  my $level = shift || 0;

  my @jobs;
  my $nJobs = ceil(scalar @inputs / $n_perJob);
  my $n = 0;
  while (my $input = pop @inputs) {
    my $jobnum = $n % $nJobs;
    $jobs[$jobnum]->{jobnumber} = $jobnum.('@' x $level);
    push(@{$jobs[$jobnum]->{inputfiles}}, $input->{inputfile});
    if (defined $input->{jobid}) {
      push(@{$jobs[$jobnum]->{jobids}}, $input->{jobid});
    }
    $n++;
  }
  return @jobs;
}

sub create_reduce_submission {
  my $job = shift;
  my $isFinal = shift || 0;
  my $jobnumber = $job->{jobnumber};

  my $hadd_inputfiles = join(" ", @{$job->{inputfiles}});

  my $hadd_outputfile = $isFinal ? abs_path($OUTFILE) :
    abs_path("$WORKDIR/Red_${jobnumber}_output.root");

  my $cmd = "$cmd_hadd $hadd_outputfile $hadd_inputfiles";
  if ($isFinal) {
    $cmd .= " && rm -rvf ".abs_path($WORKDIR);
  }

  my $qsub_cmd = $QSUB_BIN;

  $qsub_cmd .= " -N 'Red_$jobtag/$jobnumber'";

  # mails when job aborts
  $qsub_cmd .= " -m a";         # begin -m b, ends -m e
  my $user = $ENV{USER};
  $qsub_cmd .= " -M '$user\@kph.uni-mainz.de'";

  # logging: combine STDERR and STDOUT
  my $logfile = $isFinal ? "$hadd_outputfile.log"
    : abs_path("$WORKDIR/Red_$jobnumber.log");
  $qsub_cmd .= " -j oe -o '$logfile'";

  # misc stuff: batch quque, -V take over environment, walltime...
  $qsub_cmd .= " -q $queue -V -l ncpus=1 -l walltime=$walltime";

  # add depends on jobs
  my @jobids = @{$job->{jobids} || []};
  if (@jobids>0) {
    $qsub_cmd .= " -W depend=afterok:".join(':',@{$job->{jobids}});
  }
  return [$qsub_cmd, $cmd, $hadd_outputfile];
}


sub create_map_submission {
  my $job = shift;
  my $jobnumber = $job->{jobnumber};

  my $chain_output = abs_path("$WORKDIR/Map_${jobnumber}_chain.root");
  my $chain_inputfiles = join(" ", @{$job->{inputfiles}});

  my $outputfile = abs_path("$WORKDIR/Map_${jobnumber}_output.root");

  my $cmd = "$cmd_chain -o $chain_output $chain_inputfiles ".
    "&& $cmd_plot -i $chain_output -o $outputfile $plotargs";

  my $qsub_cmd = $QSUB_BIN;

  $qsub_cmd .= " -N 'Map_$jobtag/$jobnumber'";

  # mails when job aborts
  $qsub_cmd .= " -m a";         # begin -m b, ends -m e
  my $user = $ENV{USER};
  $qsub_cmd .= " -M '$user\@kph.uni-mainz.de'";

  # logging: combine STDERR and STDOUT
  my $logfile = abs_path("$WORKDIR/Map_$jobnumber.log");
  $qsub_cmd .= " -j oe -o '$logfile'";

  # misc stuff: batch quque, -V take over environment, walltime...
  $qsub_cmd .= " -q $queue -V -l ncpus=1 -l walltime=$walltime";

  # add depends on jobs
  my @jobids = @{$job->{jobids} || []};
  if (@jobids>0) {
    $qsub_cmd .= " -W depend=afterok:".join(':',@jobids);
  }

  return [$qsub_cmd, $cmd, $outputfile];
}

sub submit_job {
  my $submission = shift;
  my $qsub_cmd = $submission->[0];
  my $cmd = $submission->[1];
  # open pipe to qsub
  my($qsub_out,$qsub_in);
  my $qsub_pid = open2($qsub_out, $qsub_in, $qsub_cmd);
  print $qsub_in <<__BATCHSCRIPT;
echo QSUB_CMD="$qsub_cmd"
echo CMD="$cmd"
$cmd
__BATCHSCRIPT
  close $qsub_in;
  my $jobid = <$qsub_out>;
  unless(defined $jobid) {
      # theoretically the previous job could have also ended already,
      # but I don't think this is actually possible
      die "Did not obtain job id from qsub as output, check generated logs in $WORKDIR (probably previous jobs failed)";
  }
  chomp $jobid;
  return $jobid;
}

sub which {
  my $cmd = shift;
  open(my $p, "which $cmd 2>/dev/null |") or die "Can't open which: $!";
  my @lines = <$p>;
  close $p;
  my $exit_value = $? >> 8;
  if ($exit_value != 0 || @lines != 1) {
    return undef;
  }
  chomp $lines[0];
  return $lines[0];
}

sub get_jobs_in_queue {
  open(my $qstat, "qstat |") or die "Can't open qstat: $!";
  my @jobs_in_queue;
  while (my $line = <$qstat>) {
    chomp $line;
    my @cols  = split(/\s+/,$line);
    next if @cols != 6;         # ignore header/other lines
    my $user = $cols[2];
    next if $user ne $ENV{USER};
    my $jobid = $cols[0];
    push(@jobs_in_queue, $jobid);
  }
  close $qstat;
  return @jobs_in_queue;
}

sub print_help {
  print <<__EOF;
Usage: AntMapReduce [--clean] [--tag jobtag] [--filelist filename]
                    [--plot plottername] [--plotargs '-p plottername']

Submit jobs for mapping the given list of input files to plot cmd
given by --plot (expects standard -i for input and -o for output).
Then reduce output with Ant-hadd with additional jobs, finally
producing outputfile $jobtag.root (including log) in current
directory.

Options:

  -p, --plot  Convinience method to run plotter name,
              equivalent to '-p plottername' added to --plotargs.
              Can be specified multiple times.
  --plotargs  Provide arguments to --cmd_plot call (map step)
  --cmd_plot  Use program to convert input files to histograms (map step),
              default is "Ant-plot". If empty, only reduce using
              --cmd_hadd is done.
  --cmd_hadd  Provide alternative for Ant-hadd
  --clean     Delete output and tempdir before submission.
  --tag       Specify a custom job tag, default is Ant
  --filelist  Read from file instead of STDIN
  --mult      Specify how many files should be reduced (default 5)
  --chain     Specify how many inputs are chained for plot cmd (default 10)
  --queue     Set job queue (default: 'dflt')
  --walltime  Set walltime (default: 2:00:00, for dflt_short)
__EOF
  exit 255;
}
